{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bdac25-cde3-4194-9c48-210992214824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\n",
      "ERROR: No matching distribution found for sqlite3\n"
     ]
    }
   ],
   "source": [
    "pip install sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead518a1-69d2-4dfa-9f74-8c02f3279d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database and table created successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite (or create database if it doesn't exist)\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table for storing headlines\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS headlines (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT,\n",
    "    source TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"‚úÖ Database and table created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a01566c-87d5-4d25-87b8-12a9679bae6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ News headlines stored successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "\n",
    "# Define the news website\n",
    "URL = \"https://www.bbc.com/news\"\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all headlines\n",
    "headlines = soup.find_all(\"h2\")\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert each headline into the database\n",
    "for headline in headlines[:10]:  # Limit to 10 headlines\n",
    "    title = headline.text.strip()\n",
    "    cursor.execute(\"INSERT INTO headlines (title, source) VALUES (?, ?)\", (title, \"BBC\"))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"‚úÖ News headlines stored successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6d93d1-a343-4b99-876c-8d485d10a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Stored News Headlines:\n",
      "1. Chinese AI chatbot DeepSeek sparks market turmoil (Source: BBC)\n",
      "2. Is China's AI tool DeepSeek as good as it seems? (Source: BBC)\n",
      "3. Belgian footballer Nainggolan arrested in cocaine trafficking sting (Source: BBC)\n",
      "4. Holocaust survivors recall horrors of Auschwitz as Prince William and Kate attend London memorial (Source: BBC)\n",
      "5. Moment car accidentally drives into Philadelphia Eagles fans (Source: BBC)\n",
      "6. Is China's AI tool DeepSeek as good as it seems? (Source: BBC)\n",
      "7. Trump to sign order eliminating DEI from military (Source: BBC)\n",
      "8. Israel says eight hostages due to be freed in first phase are dead (Source: BBC)\n",
      "9. Palestinians return to north Gaza on foot, with belongings in hand (Source: BBC)\n",
      "10. Belgian footballer Nainggolan arrested in cocaine trafficking sting (Source: BBC)\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve all stored headlines\n",
    "cursor.execute(\"SELECT * FROM headlines\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nüîç Stored News Headlines:\")\n",
    "for row in rows:\n",
    "    print(f\"{row[0]}. {row[1]} (Source: {row[2]})\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595d303b-ae63-4072-be4e-7523ee6b979c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Column 'date_scraped' added successfully.\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Add the column only if it doesn't exist\n",
    "try:\n",
    "    cursor.execute(\"ALTER TABLE headlines ADD COLUMN date_scraped TEXT\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Column 'date_scraped' added successfully.\")\n",
    "except sqlite3.OperationalError:\n",
    "    print(\"‚ö†Ô∏è Column 'date_scraped' already exists.\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53f85fa-0435-4d37-9c12-6ec7f40703b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scraping BBC...\n",
      "üîç Scraping CNN...\n",
      "‚úÖ News headlines stored successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "# Define news sources\n",
    "SOURCES = {\n",
    "    \"BBC\": \"https://www.bbc.com/news\",\n",
    "    \"CNN\": \"https://edition.cnn.com/world\"\n",
    "}\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure the table exists\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS headlines (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT,\n",
    "    source TEXT,\n",
    "    date_scraped TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Function to scrape and store news\n",
    "def scrape_news():\n",
    "    for source, url in SOURCES.items():\n",
    "        print(f\"üîç Scraping {source}...\")\n",
    "\n",
    "        # Fetch webpage\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find headlines (adjust as needed for CNN structure)\n",
    "        if source == \"BBC\":\n",
    "            headlines = soup.find_all(\"h2\")\n",
    "        elif source == \"CNN\":\n",
    "            headlines = soup.find_all(\"span\", class_=\"container__headline-text\")\n",
    "\n",
    "        # Store headlines in the database\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        for headline in headlines[:10]:  # Limit to top 10 headlines\n",
    "            title = headline.text.strip()\n",
    "            cursor.execute(\"INSERT INTO headlines (title, source, date_scraped) VALUES (?, ?, ?)\", \n",
    "                           (title, source, timestamp))\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ News headlines stored successfully!\")\n",
    "\n",
    "# Run the scraper\n",
    "scrape_news()\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2daf48f6-88f6-4044-84ba-4dabe0fe942e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title source date_scraped\n",
      "0   1  Chinese AI chatbot DeepSeek sparks market turmoil    BBC         None\n",
      "1   2   Is China's AI tool DeepSeek as good as it seems?    BBC         None\n",
      "2   3  Belgian footballer Nainggolan arrested in coca...    BBC         None\n",
      "3   4  Holocaust survivors recall horrors of Auschwit...    BBC         None\n",
      "4   5  Moment car accidentally drives into Philadelph...    BBC         None\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_sql(\"SELECT * FROM headlines\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1422cc86-c1ca-4326-9d86-f124b70b4dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Tables in the database: [('headlines',), ('sqlite_sequence',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"news.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# List all tables in the database\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"üìÇ Tables in the database:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5de8bf-0c63-4f26-9a3e-a6391fa51b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
